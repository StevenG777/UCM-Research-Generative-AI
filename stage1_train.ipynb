{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=128, help=\"size of the batches\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=1000, help=\"interval between image samples\")\n",
    "parser.add_argument(\"--save_interval\", type=int, default=50, help=\"interval between saving model\")\n",
    "parser.add_argument('--model_path', type=str, default='/home/rnap/data/emotion/model', help='model_path') \n",
    "opt = parser.parse_args()\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(opt.latent_dim, 256, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, opt.channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        img = self.model(z)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(opt.channels, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        validity = validity.squeeze(1).squeeze(2)\n",
    "        return validity\n",
    "\n",
    "\n",
    "def adversarial_loss(output, target):\n",
    "    loss = F.binary_cross_entropy(output, target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def save_model(opt, generator, discriminator, optimizer_G, optimizer_D, current_epoch):\n",
    "    out = os.path.join(opt.model_path, \"checkpoint_{}.tar\".format(current_epoch))\n",
    "    state = {\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'optimizer_G': optimizer_G.state_dict(),\n",
    "        'optimizer_D': optimizer_D.state_dict(),\n",
    "        'epoch': current_epoch\n",
    "    }\n",
    "    torch.save(state, out)\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "            transforms.Lambda(lambda x: (x + 1.0) / 2.0)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "        image = Image.open(img_path)\n",
    "        image = self.transform(image)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "csv_file = \"csv/neutral.csv\"\n",
    "cid = CustomImageDataset(csv_file)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    cid,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = optim.SGD(generator.parameters(), lr=0.0002, momentum=0.5)\n",
    "optimizer_D = optim.SGD(discriminator.parameters(), lr=0.0002, momentum=0.5)\n",
    "\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        valid = Tensor(imgs.size(0), 1).fill_(1.0)\n",
    "        fake = Tensor(imgs.size(0), 1).fill_(0.0)\n",
    "\n",
    "        real_imgs = imgs.type(Tensor)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim)))\n",
    "\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %.4f] [G loss: %.4f]\"\n",
    "                  % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "        if (epoch + 1) % opt.save_interval == 0:\n",
    "            save_model(opt, generator, discriminator, optimizer_G, optimizer_D, epoch + 1)\n",
    "\n",
    "\n",
    "    generator_losses.append(g_loss.item())\n",
    "    discriminator_losses.append(d_loss.item())\n",
    "\n",
    "plt.plot(generator_losses, label='Generator Loss')\n",
    "plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('plot.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
